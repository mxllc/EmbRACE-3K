<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="description"
    content="EmbRACE-3K: Embodied Reasoning and Action in Complex Environments">
  <meta name="keywords"
    content="Hand-object iteractions; Motion refinement; Inverse problems; Generative priors; Diffusion models">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta property="og:type" content="video.other" />
  <title>EmbRACE-3K:Embodied Reasoning and Action in Complex Environments</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <!-- <link rel="stylesheet" href="./static/css/styles.css"> -->
  <link rel="icon" href="./static/images/icon-2-new.png">
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
  <script src="assets/js/video_comparison.js"></script>

  <script src="https://polyfill.io/v3/polyfill.js?features=IntersectionObserver"></script>
  <!-- <script src="./static/js/yall.js"></script> -->
  <script>
    yall(
      {
        observeChanges: true
      }
    );
  </script>
  <!-- <script src="./static/js/scripts.js"></script> -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.5.0/js/bootstrap.bundle.min.js"></script>
  <script src="https://uploads-ssl.webflow.com/51e0d73d83d06baa7a00000f/js/webflow.fd002feec.js"></script>
  <script type="module" src="https://unpkg.com/@google/model-viewer@2.0.1/dist/model-viewer.min.js"></script>
  <style>
    .horizontal_line {
      width: 90%;
      height: 5px;
      border-top: 5px dotted black;
      line-height: 80%;
    }

    .line {
      border-bottom: 1px solid rgb(172, 170, 170);
      margin-top: 1px;
      margin-left: 130px;
      width: 80%;
    }
  </style>
</head>

<body>
  <!-- <div> -->
  <!-- <br>
  <br>
  <br> -->
  <!-- </div> -->
  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h2 class="title is-2 publication-title embrace-title">
              <span class="em">Emb</span><span class="r">R</span><span class="a">A</span><span class="c">C</span><span class="e">E</span><span class="dash">-</span>3K
              <br>
              <span style="font-size:36px; font-weight:normal;">
                <span class="subtitle-highlight1">Emb</span>odied
                <span class="subtitle-highlight2">R</span>easoning and
                <span class="subtitle-highlight3">A</span>ction in
                <span class="subtitle-highlight4">C</span>omplex
                <span class="subtitle-highlight5">E</span>nvironments
              </span>
            </h2>
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="https://mxllc.github.io/">Mingxian Lin</a><sup>1*</sup>,</span>
              <span class="author-block">
                <a href="https://aaron-weihuang.com/">Wei Huang</a><sup>1*</sup>,</span>
              <span class="author-block">
                <a href="https://liyitang22.github.io/">Yitang Li</a><sup>2</sup>,</span>
              <span class="author-block">
                <a href="https://www.linkedin.com/in/ronniejiang">Chengjie Jiang</a><sup>3</sup>,</span>
              <span class="author-block">
                <a href="https://github.com/wukui-muc">Kui Wu</a><sup>4</sup>,</span><br>
              <span class="author-block">
                <a href="https://fangweizhong.xyz/">Fangwei Zhong</a><sup>4</sup>,</span>
              <span class="author-block">
                <a href="http://thesouthfrog.com/about.me/">Shengju Qian</a><sup>3</sup>,</span>
              <span class="author-block">
                <a href="https://scholar.google.com/citations?user=2Z1GJ50AAAAJ">Xin Wang</a><sup>3</sup>,</span>
              <span class="author-block">
                <a href="https://xjqi.github.io/">Xiaojuan Qi</a><sup>1†</sup>,</span>
            </div>
  
            <div class="is-size-5 publication-authors">
              <span class="author-block"><sup>1</sup>The University of Hong Kong,</span> 
              <span class="author-block"><sup>2</sup>Tsinghua University,</span>
              <span class="author-block"><sup>3</sup>Tencent,</span> 
              <span class="author-block"><sup>4</sup>Beijing Normal University</span> 
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block"><sup>*</sup>Equal Contribution, </span>
              <span class="author-block"><sup>†</sup>Corresponding Author</span>
          </div>


  
            <!-- <div class="is-size-4 publication-authors">
              <span style="font-weight:bold">CVPR 2025</span>
            </div> -->

            <div class="column has-text-centered">
            <div class="publication-links">

              <!-- <span class="link-block">
                <a href="http://arxiv.org/abs/2503.07481"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span> -->
              <span class="link-block">
                <a 
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>

<!--               <span class="link-block">
                <a href="./static/pdfs/Parameterized_Quasi_Physical_Simulators_for_Dexterous_Manipulations_Transfer.pdf"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span> -->
<!--               <span class="link-block">
                <a href="https://huggingface.co/spaces/xymeow7/quasi-physical-sims"
                   class="external-link button is-normal is-rounded is-dark">
                  <!-- <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span> 
                  <span>🤗 Gradio Demo </span>
                </a>
              </span> -->
              
              <span class="link-block">
                <a href="https://github.com/mxllc/EmbRACE-3K"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code(Coming Soon)</span>
                  </a>
              </span>

              <!-- <span class="link-block">
                <a href="https://www.youtube.com/watch?v=eJ2G_tpUE8Y"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span> -->
<!--               <span class="link-block">
                <a href="https://docs.google.com/presentation/d/1nRCxP_5P9Pcni53zvyRZ_PEDIaQeE8FF/edit?usp=sharing&ouid=103893738370724206774&rtpof=true&sd=true"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fab fa-slideshare"></i>
                  </span>
                  <span>Slides (114MB)</span>
                </a>
              </span> -->
              <span class="link-block">
                <a href="./static/EmbRACE_3K_supp.pdf"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Supp</span>
                </a>
              </span>
            </div>

          </div>
            
          </div>
          
        </div>
        
  </section>




  <section class="hero teaser">
    <div class="container is-max-desktop">
      <div class="hero-body">
        <video id="teaser" class="lazy" poster="static/images/teaser.png" autoplay muted loop height="50%">
          <!-- <source data-src="static/videos-lowres/demo-video-4-compressed.mp4"
                type="video/mp4"> -->
        </video>
      </div>
    </div>

    <!-- <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3"><span style="color: rgb(0, 0, 0); font-weight:bold">Video</span></h2>
        <div class="publication-video">
          <iframe width="560" height="315" src="https://www.youtube.com/embed/eJ2G_tpUE8Y?si=Gp7NJoYmhQbc0HJ2" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
        </div>
    </div>
  </div> -->
  </section>

  <!-- <section class="hero is-light is-small">
    <div class="hero-body">
      <div class="container">
        <div id="results-carousel" class="carousel results-carousel">
          <div class="item item-fullbody">
            <video poster="" id="fullbody" class="lazy" autoplay playsinline controls muted loop height="10%">
              <source data-src="static/show/s1.mp4" type="video/mp4">
            </video>
          </div>

          <div class="item item-fullbody">
            <video poster="" id="fullbody" class="lazy" autoplay playsinline controls muted loop height="10%">
              <source data-src="static/show/s5.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-fullbody">
            <video poster="" id="fullbody" class="lazy" autoplay playsinline controls muted loop height="10%">
              <source data-src="./static/feature/sta2.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-fullbody">
            <video poster="" id="fullbody" class="lazy" autoplay playsinline controls muted loop height="10%">
              <source data-src="static/show/s4.mp4" type="video/mp4">
            </video>
          </div>
           <div class="item item-fullbody">
            <video poster="" id="fullbody" class="lazy" autoplay playsinline controls muted loop height="10%">
              <source data-src="static/show/s7new.mp4" type="video/mp4">
            </video>
          </div> -->
<!--           <div class="item item-fullbody">
            <video poster="" id="fullbody" class="lazy" autoplay playsinline controls muted loop height="10%">
              <source data-src="static/show/s2.mp4" type="video/mp4">
            </video>
          </div> -->

<!-- 
           <div class="item item-fullbody">
            <video poster="" id="fullbody" class="lazy" autoplay playsinline controls muted loop height="10%">
              <source data-src="static/show/s6new.mp4" type="video/mp4">
            </video>
          </div> --> 
          <!-- <div class="item item-fullbody">
            <video poster="" id="fullbody" class="lazy" autoplay playsinline controls muted loop height="10%">
              <source data-src="./static/feature/MyVideo_2.mp4" type="video/mp4">
            </video>
          </div> -->
<!--           <div class="item item-fullbody">
            <video poster="" id="fullbody" class="lazy" autoplay playsinline controls muted loop height="10%">
              <source data-src="static/show/objects_generalization/11.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-fullbody">
            <video poster="" id="fullbody" class="lazy" autoplay playsinline controls muted loop height="10%">
              <source data-src="static/show/objects_generalization/12.mp4" type="video/mp4">
            </video>
          </div> -->

        <!-- </div>
      </div>
    </div>
  </section> --> 


  <section class="section">
    <div class="container is-max-desktop">
      <!-- Abstract. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3"><span style="color: rgb(0, 0, 0); font-weight:bold">Abstract</span></h2>
          <div class="content has-text-justified">
            <p>
              Recent advanced vision-language models (VLMs) have demonstrated strong performance on passive, offline image and video understanding tasks. 
              However, their effectiveness in embodied settings—which require online interaction and active scene understanding—remains limited. 
              In such scenarios, an agent perceives the environment from a first-person perspective, with each action dynamically shaping subsequent observations. 
              Even state-of-the-art models such as GPT-4o, Claude 3.5 Sonnet, and Gemini 2.5 Pro struggle in open-environment interactions, exhibiting clear limitations in spatial reasoning and long-horizon planning. 
              These limitations are further emphasized by our empirical analysis of modern VLMs, which reveals consistent failure modes when applied to embodied tasks. 
              To address this gap, we introduce 
              <span class="embrace-title">
                <span class="em">Em</span><span class="r">R</span><span class="a">A</span><span class="c">C</span><span class="e">E</span><span class="dash">-</span>3K,
              a dataset of over <b>3,000</b> language-guided tasks situated in diverse, photorealistic environments constructed using Unreal Engine and the UnrealCV-Zoo framework. 
              The tasks encompass a wide range of embodied challenges, including navigation, object manipulation, and multi-stage goal execution. 
              Each task unfolds as a multi-step trajectory, pairing first-person visual observations with high-level instructions, grounded actions, and natural language rationales that express the agent's intent at every step. 
              This design results in fine-grained, temporally grounded annotations that closely align perception with decision-making. 
              In total, the dataset contains approximately <b>26,000</b> decision steps, each annotated with multimodal context and step-wise reasoning. 
              Using <span class="embrace-title">
                <span class="em">Em</span><span class="r">R</span><span class="a">A</span><span class="c">C</span><span class="e">E</span><span class="dash">-</span>3K, we establish a benchmark to evaluate the embodied reasoning capabilities of VLMs such as GPT-4o, Gemini 2.5 Pro, and Qwen2.5-VL-7B, across three key dimensions: Exploration, Dynamic Spatial-Semantic Reasoning, and Multi-stage Goal Execution. In zero-shot settings, all models achieve success rates below 20%, underscoring the challenge posed by our benchmark and the current limitations of VLMs in interactive environments. 
              To demonstrate the utility of <span class="embrace-title">
                <span class="em">Em</span><span class="r">R</span><span class="a">A</span><span class="c">C</span><span class="e">E</span><span class="dash">-</span>3K, we further fine-tune Qwen2.5-VL-7B using supervised learning followed by reinforcement learning. 
              This approach yields substantial improvements across all three challenge categories, highlighting the dataset's effectiveness in enabling the development of embodied reasoning capabilities. 
              Our dataset, evaluation benchmark, and code will be made publicly available to support future research in this area.
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>


  <section class="section">
    <div class="container is-max-desktop">
      <!-- Section Title -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3"><span style="color: rgb(0, 0, 0); font-weight:bold">Data Collection</span></h2>
          <div class="content has-text-justified">
            <p>
              The <span class="embrace-title">
                <span class="em">Em</span><span class="r">R</span><span class="a">A</span><span class="c">C</span><span class="e">E</span><span class="dash">-</span>3K
              </span> dataset is built in four stages: (1) sampling diverse 6-DoF agent poses with ego views in virtual environments, (2) generating grounded task instructions using Gemini, (3) collecting human demonstrations, and (4) annotating each action with step-wise natural language reasoning to explain agent decisions and enhance interpretability.
            </p>
          </div>
        </div>
      </div>

      <!-- Full-width Image -->
      <div class="columns is-centered">
        <div class="column is-full has-text-centered">
          <figure class="image">
            <img src="./static/images/pipeline.png" alt="Data Collection Pipeline">
          </figure>
        </div>
      </div>
  </section>



  <section class="section">
    <div class="container is-max-desktop">
      <!-- Section Title -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">
            <span style="color: rgb(0, 0, 0); font-weight:bold">Data Statistics</span>
          </h2>
        </div>
      </div>

      <!-- Carousel -->
      <section class="hero is-light is-small">
        <div class="hero-body">
          <div class="container">
            <div id="statistics-carousel" class="carousel results-carousel">

              <div class="item">
                <figure class="image has-text-centered">
                  <img src="./static/images/trajectory_distribution.png" alt="Trajectory Distribution"
                      style="max-height: 400px; object-fit: contain; margin: auto;">
                  <figcaption style="margin-top: 0.5em;">Trajectory Distribution</figcaption>
                </figure>
              </div>

              <div class="item">
                <figure class="image has-text-centered">
                  <img src="./static/images/word_cloud.png" alt="Instruction Word Cloud"
                      style="max-height: 400px; object-fit: contain; margin: auto;">
                  <figcaption style="margin-top: 0.5em;">Instruction Word Cloud</figcaption>
                </figure>
              </div>

              <div class="item">
                <figure class="image has-text-centered">
                  <img src="./static/images/type_distribution.png" alt="Task Type Distribution"
                      style="max-height: 400px; object-fit: contain; margin: auto;">
                  <figcaption style="margin-top: 0.5em;">Task Type Distribution</figcaption>
                </figure>
              </div>

            </div>
          </div>
        </div>
      </section>
    </div>
  </section>




 <section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-full">
        <h2 class="title is-3">
          <span style="color: rgb(0, 0, 0); font-weight:bold">Data Example</span>
        </h2>
      </div>
    </div>

    <!-- Instruction -->
    <div class="has-text-centered mb-5">
      <p id="instruction-text"></p>
    </div>

    <!-- Content Row -->
    <div class="columns is-vcentered">
      <!-- Image -->
      <div class="column is-half has-text-centered">
        <figure class="image">
          <img id="step-image" src="" alt="step" style="max-height: 500px; object-fit: contain;">
        </figure>
      </div>

      <!-- Text + Buttons -->
      <div class="column is-half" style="display: flex; flex-direction: column; justify-content: space-between; height: 500px;">
  <div class="content" style="font-size: 18px; overflow-y: auto; max-height: 420px; padding-right: 8px;">
    <p id="step-index" style="font-weight: bold; font-size: 22px; color: #9C27B0;"></p>
    <p id="step-thinking"></p>
    <p id="step-action"></p>
  </div>

  <!-- 按钮居中对称 -->
  <div class="buttons is-centered mt-3" style="gap: 12px;">
    <button id="prev-btn" class="button is-link is-light">← Last Step</button>
    <button id="next-btn" class="button is-link is-light">Next Step →</button>
  </div>
</div>
</section>








  <div class="container is-full-hd is-centered">
    <div class="line"></div>
  </div>







  <script src="https://polyfill.io/v3/polyfill.js?features=IntersectionObserver"></script>
  <!-- <script src="/assets/js/yall.js"></script> -->
  <script>
    yall(
      {
        observeChanges: true
      }
    );
  </script>
  <!-- <script src="/assets/js/scripts.js"></script> -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.5.0/js/bootstrap.bundle.min.js"></script>
  <script src="https://uploads-ssl.webflow.com/51e0d73d83d06baa7a00000f/js/webflow.fd002feec.js"></script>

  <script>
    document.addEventListener("DOMContentLoaded", function () {
      var lazyVideos = [].slice.call(document.querySelectorAll("video.lazy"));
      if ("IntersectionObserver" in window) {
        var lazyVideoObserver = new IntersectionObserver(function (entries, observer) {
          entries.forEach(function (video) {
            if (video.isIntersecting) {
              for (var source in video.target.children) {
                var videoSource = video.target.children[source];
                if (typeof videoSource.tagName === "string" && videoSource.tagName === "SOURCE") {
                  videoSource.src = videoSource.dataset.src;
                }
              }
              video.target.load();
              video.target.classList.remove("lazy");
              lazyVideoObserver.unobserve(video.target);
            }
          });
        });
        lazyVideos.forEach(function (lazyVideo) {
          lazyVideoObserver.observe(lazyVideo);
        });
      }
    });
  </script>


  <script>
    function change_stochastic() {
      console.info("hhh\n");
      const showMoreBtn = document.getElementById('showMoreBtn_stochastic');
      if (showMoreBtn.innerText == 'More results') {
        showMoreBtn.innerText = 'Hide';
      } else {
        showMoreBtn.innerText = 'More results';
      }
    };

    function change_arctic() {
      console.info("hhh\n");
      const showMoreBtn = document.getElementById('showMoreBtn_arctic');
      if (showMoreBtn.innerText == 'More results') {
        showMoreBtn.innerText = 'Hide';
      } else {
        showMoreBtn.innerText = 'More results';
      }
    };

    function change_hoi4d() {
      console.info("hhh\n");
      const showMoreBtn = document.getElementById('showMoreBtn_hoi4d');
      if (showMoreBtn.innerText == 'More results') {
        showMoreBtn.innerText = 'Hide';
      } else {
        showMoreBtn.innerText = 'More results';
      }
    };

    function change_grabbeta() {
      console.info("hhh\n");
      const showMoreBtn = document.getElementById('showMoreBtn_grabbeta');
      if (showMoreBtn.innerText == 'More results') {
        showMoreBtn.innerText = 'Hide';
      } else {
        showMoreBtn.innerText = 'More results';
      }
    };

    function change_grab() {
      console.info("hhh\n");
      const showMoreBtn = document.getElementById('showMoreBtn_grab');
      if (showMoreBtn.innerText == 'More results') {
        showMoreBtn.innerText = 'Hide';
      } else {
        showMoreBtn.innerText = 'More results';
      }
    };

    function change_appli() {
      console.info("hhh\n");
      const showMoreBtn = document.getElementById('showMoreBtn_appli');
      if (showMoreBtn.innerText == 'More results') {
        showMoreBtn.innerText = 'Hide';
      } else {
        showMoreBtn.innerText = 'More results';
      }
    };
  </script>


  <div class="container is-full-hd is-centered">
    <!-- <hr class="solid; " color="blue" noshade> -->
    <!-- <hr width="100%" size="2" color="blue" noshade> -->
    <div class="line"></div>
  </div>


  <section class="section " id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title is-3 has-text-centered">BibTeX</h2>
      <pre><code>@article{huang2024deformable,
        title={Deformable Radial Kernel Splatting},
        author={Huang, Yi-Hua and Lin, Ming-Xian and Sun, Yang-Tian and Yang, Ziyi and Lyu, Xiaoyang and Cao, Yan-Pei and Qi, Xiaojuan},
        journal={arXiv preprint arXiv:2412.11752},
        year={2024}
      }</code></pre>
    </div>
  </section>

  <section class="section" id="Contact">
    <div class="container is-max-desktop content has-text-centered">
      <!-- <h2 class="title">Contact</h2> -->
      <h2 class="title is-3">Contact</h2>
        <p>
          Please contact us at <a href="mailto:lmx.mingxian@gmail.com">lmx.mingxian@gmail.com</a> if you have any question. 
        </p>
    </div>
  </section>
  


  <footer class="footer">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">
            <p>
              The template is adapted from <a href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>. We thank
              authors for their codebase.
            </p>
          </div>
        </div>
      </div>
    </div>
  </footer>
</body>


<script>
  bulmaCarousel.attach('#statistics-carousel', {
    slidesToScroll: 1,
    slidesToShow: 1,
    infinite: true,
    autoplay: false,
    pagination: true,
    navigation: true
  });
</script>


<script>
  const basePath = "./static/data/t0/x01100_y-00798_z0117_i2/";
  const geminiPath = basePath + "gemini.json";
  const infoPath = basePath + "infos.json";

  let currentIndex = 0;
  let steps = [];

  const imgEl = document.getElementById("step-image");
  const indexEl = document.getElementById("step-index");
  const actionEl = document.getElementById("step-action");
  const thinkingEl = document.getElementById("step-thinking");
  const instructionEl = document.getElementById("instruction-text");
  const prevBtn = document.getElementById("prev-btn");
  const nextBtn = document.getElementById("next-btn");

  const ACTION_COLORS = {
    "MoveForward": "#388E3C",
    "MoveBackward": "#388E3C",
    "JumpForward": "#388E3C",
    "TurnLeft": "#7C4DFF",
    "TurnRight": "#7C4DFF",
    "LookUp": "#EA80FC",
    "LookDown": "#EA80FC",
    "LookBack": "#EA80FC",
    "LookHand": "#EA80FC",
    "OpenDoor": "#E64A19",
    "PickObject": "#E64A19",
    "DropObject": "#E64A19",
    "Finish": "#FBC02D",
    "MidwayTarget": "#29B6F6"
  };

  function formatInstruction(task) {
    return (
      `<span style="font-size:26px; font-weight:bold; color:#444;">Instruction:</span> ` +
      `<span style="font-size:26px; font-weight:bold; color:#FF5722;">${task}</span>`
    );
  }

  function formatAction(action) {
    const color = ACTION_COLORS[action] || "#90A4AE";
    return `<b><span style='color:#40C4FF;'>Action:</span></b> <span style='font-size:20px; color:${color};'>${action}</span>`;
  }

  function formatThinking(thinking) {
    return `<b><span style='font-weight:bold; color:#FFB300;'>Thinking:</span></b> <span style='font-size:20px; color:#444;'>${thinking}</span>`;
  }

  function updateStep(index) {
    const step = steps[index];
    imgEl.src = basePath + step.image_name;
    indexEl.innerHTML = `<span style="font-size:22px;">Step: ${index}</span>`;
    thinkingEl.innerHTML = formatThinking(step.thinking);
    actionEl.innerHTML = formatAction(step.action);

    prevBtn.disabled = index === 0;
    nextBtn.disabled = index === steps.length - 1;
  }

  prevBtn.addEventListener("click", () => {
    if (currentIndex > 0) {
      currentIndex -= 1;
      updateStep(currentIndex);
    }
  });

  nextBtn.addEventListener("click", () => {
    if (currentIndex < steps.length - 1) {
      currentIndex += 1;
      updateStep(currentIndex);
    }
  });

  // 加载数据
  Promise.all([
    fetch(geminiPath).then(res => res.json()),
    fetch(infoPath).then(res => res.json())
  ]).then(([stepData, infoData]) => {
    steps = stepData;
    instructionEl.innerHTML = formatInstruction(infoData.Instruction);
    updateStep(currentIndex);
  }).catch(err => {
    console.error("❌ Failed to load data:", err);
  });
</script>





</html>
